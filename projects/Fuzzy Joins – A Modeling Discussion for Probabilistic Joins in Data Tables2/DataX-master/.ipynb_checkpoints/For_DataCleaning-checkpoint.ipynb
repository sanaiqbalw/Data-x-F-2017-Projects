{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cyril/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Cyril/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import grid_search\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Defining the filling empty values function </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def fillEmpty(original_df,colnum,flag):\n",
    "    # assumed: df is the dataframe to operate on,\n",
    "    # colnum is the column number with missing values\n",
    "    # flag = 0/1 is whether it is a classification or regression problem\n",
    "    \n",
    "    # copying the original dataframe\n",
    "    df = original_df.copy()\n",
    "    \n",
    "    # testing for valid flag\n",
    "    if(flag != 0 and flag != 1):\n",
    "        print('Invalid input flag')\n",
    "        sys.exit()\n",
    "    # testing for valid column number\n",
    "    number_of_columns = len(list(original_df))\n",
    "    if(colnum < 0 or colnum >= number_of_columns):\n",
    "        print('Invalid input column number')\n",
    "        sys.exit()\n",
    "    # testing for the existence of empty column values\n",
    "    a = df.iloc[:, [colnum]].isnull()\n",
    "    idx = []\n",
    "    for col in a:\n",
    "        i=0\n",
    "        for c in a[col]:\n",
    "            if(c == True):\n",
    "                idx.append(i)\n",
    "            i=i+1\n",
    "    if(len(idx) == 0):\n",
    "        print('No empty values for input column number')\n",
    "        sys.exit()\n",
    "    \n",
    "    # now can start pre-processing:\n",
    "    # This converts all columns with \"object\" variables (AKA string) into numbers, and creates a dictionary  \n",
    "    char_cols = df.dtypes.pipe(lambda x: x[x == 'object']).index\n",
    "    label_mapping = {}\n",
    "    for c in char_cols:\n",
    "        df[c], label_mapping[c] = pd.factorize(df[c])\n",
    "        \n",
    "    # for the sake of classifying/ predicting current column,\n",
    "    # with other columns may having null values,\n",
    "    # we will replace the other columns' null val\n",
    "    for c in df:\n",
    "        df[c] = df[c].fillna(df[c].mean())\n",
    "\n",
    "    # although some issue with the above may arise if null:\n",
    "    # re-set all null values to null\n",
    "    df.iloc[idx,[colnum]] = np.nan\n",
    "    # Accessing the rows without empty values at colnum\n",
    "    df_complete = df.dropna()\n",
    "    df_complete.shape\n",
    "    # Accessing the rows with empty values at colnum\n",
    "    df_empty = df.iloc[idx]\n",
    "    df_empty.shape\n",
    "    # Splitting complete rows into target/features\n",
    "    features = df_complete.drop(df.columns[[colnum]], axis=1)\n",
    "    target_variable = df_complete.iloc[:, [colnum]]\n",
    "    # Splitting the rows with empty colnum into features and response (which is what we're predicting)\n",
    "    features_empty = df_empty.drop(df.columns[[colnum]], axis=1)\n",
    "    \n",
    "    # now can start classifying/ predicting:\n",
    "    if(flag==0): # classification\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        print('Classifying...')\n",
    "        print()\n",
    "        # Training random forest\n",
    "        randFor = RandomForestClassifier(n_estimators = 20)\n",
    "        randFor.fit(features, target_variable)\n",
    "        # Accuracy on the training set set\n",
    "        print('Training score: ',randFor.score(features, target_variable))\n",
    "        # Set of \"City Group\" predictions for the rows with empty values \n",
    "        y_pred_randFor = randFor.predict(features_empty)\n",
    "        print(y_pred_randFor)\n",
    "    else: # prediction\n",
    "        from sklearn.linear_model import Ridge\n",
    "        print('Predicting...')\n",
    "        print()\n",
    "        # Ridge Regression\n",
    "        ridgereg = Ridge(normalize=True)\n",
    "        ridgereg.fit(features,target_variable)\n",
    "        y_pred_ridge = ridgereg.predict(features_empty)\n",
    "        print (y_pred_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the second version of fillEmpty:\n",
    "# instead of providing a column number,\n",
    "# the user should provide a column name\n",
    "\n",
    "import sys\n",
    "\n",
    "def fillEmpty2(original_df,colname,flag):\n",
    "    # assumed: df is the dataframe to operate on,\n",
    "    # colnum is the column number with missing values\n",
    "    # flag = 0/1 is whether it is a classification or regression problem\n",
    "    \n",
    "    # copying the original dataframe\n",
    "    df = original_df.copy()\n",
    "    \n",
    "    # testing for valid flag\n",
    "    if(flag != 0 and flag != 1):\n",
    "        print('Invalid input flag')\n",
    "        sys.exit()\n",
    "    # testing for valid column number\n",
    "    number_of_columns = len(list(original_df))\n",
    "    if not(colname in df):\n",
    "        print('Invalid input column name')\n",
    "        sys.exit()\n",
    "    # retrieve the column number\n",
    "    colnum = df.columns.get_loc(colname)\n",
    "    # testing for the existence of empty column values\n",
    "    a = df.iloc[:, [colnum]].isnull()\n",
    "    idx = []\n",
    "    for col in a:\n",
    "        i=0\n",
    "        for c in a[col]:\n",
    "            if(c == True):\n",
    "                idx.append(i)\n",
    "            i=i+1\n",
    "    if(len(idx) == 0):\n",
    "        print('No empty values for input column number')\n",
    "        sys.exit()\n",
    "    \n",
    "    # now can start pre-processing:\n",
    "    # This converts all columns with \"object\" variables (AKA string) into numbers, and creates a dictionary  \n",
    "    char_cols = df.dtypes.pipe(lambda x: x[x == 'object']).index\n",
    "    label_mapping = {}\n",
    "    for c in char_cols:\n",
    "        df[c], label_mapping[c] = pd.factorize(df[c])\n",
    "        \n",
    "    # for the sake of classifying/ predicting current column,\n",
    "    # with other columns may having null values,\n",
    "    # we will replace the other columns' null val\n",
    "    for c in df:\n",
    "        df[c] = df[c].fillna(df[c].mean())\n",
    "\n",
    "    # although some issue with the above may arise if null:\n",
    "    # re-set all null values to null\n",
    "    df.iloc[idx,[colnum]] = np.nan\n",
    "    # Accessing the rows without empty values at colnum\n",
    "    df_complete = df.dropna()\n",
    "    df_complete.shape\n",
    "    # Accessing the rows with empty values at colnum\n",
    "    df_empty = df.iloc[idx]\n",
    "    df_empty.shape\n",
    "    # Splitting complete rows into target/features\n",
    "    features = df_complete.drop(df.columns[[colnum]], axis=1)\n",
    "    target_variable = df_complete.iloc[:, [colnum]]\n",
    "    # Splitting the rows with empty colnum into features and response (which is what we're predicting)\n",
    "    features_empty = df_empty.drop(df.columns[[colnum]], axis=1)\n",
    "    \n",
    "    # now can start classifying/ predicting:\n",
    "    if(flag==0): # classification\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        print('Classifying...')\n",
    "        print()\n",
    "        # Training random forest\n",
    "        randFor = RandomForestClassifier(n_estimators = 20)\n",
    "        randFor.fit(features, target_variable)\n",
    "        # Accuracy on the training set set\n",
    "        print('Training score: ',randFor.score(features, target_variable))\n",
    "        # Set of \"City Group\" predictions for the rows with empty values \n",
    "        y_pred_randFor = randFor.predict(features_empty)\n",
    "        print(y_pred_randFor)\n",
    "    else: # prediction\n",
    "        from sklearn.linear_model import Ridge\n",
    "        print('Predicting...')\n",
    "        print()\n",
    "        # Ridge Regression\n",
    "        ridgereg = Ridge(normalize=True)\n",
    "        ridgereg.fit(features,target_variable)\n",
    "        y_pred_ridge = ridgereg.predict(features_empty)\n",
    "        print (y_pred_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the third version of fillEmpty:\n",
    "# it fills the empty values of the dataframe,\n",
    "# and creates a new column indicating if\n",
    "# a column value was synthesized\n",
    "\n",
    "import sys\n",
    "\n",
    "def fillEmptyNew(original_df,colname,flag):\n",
    "    # assumed: df is the dataframe to operate on,\n",
    "    # colnum is the column number with missing values\n",
    "    # flag = 0/1 is whether it is a classification or regression problem\n",
    "    \n",
    "    # copying the original dataframe\n",
    "    df = original_df.copy()\n",
    "    \n",
    "    # testing for valid flag\n",
    "    if(flag != 0 and flag != 1):\n",
    "        print('Invalid input flag')\n",
    "        sys.exit()\n",
    "    # testing for valid column number\n",
    "    number_of_columns = len(list(original_df))\n",
    "    if not(colname in df):\n",
    "        print('Invalid input column name')\n",
    "        sys.exit()\n",
    "    # retrieve the column number\n",
    "    colnum = df.columns.get_loc(colname)\n",
    "    # testing for the existence of empty column values\n",
    "    a = df.iloc[:, [colnum]].isnull()\n",
    "    idx = []\n",
    "    for col in a:\n",
    "        i=0\n",
    "        for c in a[col]:\n",
    "            if(c == True):\n",
    "                idx.append(i)\n",
    "            i=i+1\n",
    "    if(len(idx) == 0):\n",
    "        print('No empty values for input column number')\n",
    "        sys.exit()\n",
    "    \n",
    "    # now can start pre-processing:\n",
    "    # This converts all columns with \"object\" variables (AKA string) into numbers, and creates a dictionary  \n",
    "    char_cols = df.dtypes.pipe(lambda x: x[x == 'object']).index\n",
    "    label_mapping = {}\n",
    "    for c in char_cols:\n",
    "        df[c], label_mapping[c] = pd.factorize(df[c])\n",
    "        \n",
    "    # for the sake of classifying/ predicting current column,\n",
    "    # with other columns may having null values,\n",
    "    # we will replace the other columns' null val\n",
    "    for c in df:\n",
    "        df[c] = df[c].fillna(df[c].mean())\n",
    "\n",
    "    # although some issue with the above may arise if null:\n",
    "    # re-set all null values to null\n",
    "    df.iloc[idx,[colnum]] = np.nan\n",
    "    # Accessing the rows without empty values at colnum\n",
    "    df_complete = df.dropna()\n",
    "    df_complete.shape\n",
    "    # Accessing the rows with empty values at colnum\n",
    "    df_empty = df.iloc[idx]\n",
    "    df_empty.shape\n",
    "    # Splitting complete rows into target/features\n",
    "    features = df_complete.drop(df.columns[[colnum]], axis=1)\n",
    "    target_variable = df_complete.iloc[:, [colnum]]\n",
    "    # Splitting the rows with empty colnum into features and response (which is what we're predicting)\n",
    "    features_empty = df_empty.drop(df.columns[[colnum]], axis=1)\n",
    "    \n",
    "    # now can start classifying/ predicting:\n",
    "    y_new = []\n",
    "    if(flag==0): # classification\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        print('Classifying...')\n",
    "        print()\n",
    "        # Training random forest\n",
    "        randFor = RandomForestClassifier(n_estimators = 20)\n",
    "        randFor.fit(features, target_variable)\n",
    "        # Accuracy on the training set set\n",
    "        print('Training score: ',randFor.score(features, target_variable))\n",
    "        # Set of \"City Group\" predictions for the rows with empty values \n",
    "        y_new = randFor.predict(features_empty)\n",
    "    else: # prediction\n",
    "        from sklearn.linear_model import Ridge\n",
    "        print('Predicting...')\n",
    "        print()\n",
    "        # Ridge Regression\n",
    "        ridgereg = Ridge(normalize=True)\n",
    "        ridgereg.fit(features,target_variable)\n",
    "        y_new = ridgereg.predict(features_empty)\n",
    "    # add the new values to the dataframe\n",
    "    df.iloc[idx,[colnum]] = y_new\n",
    "    df[colname+'_synthesized'] = 0\n",
    "    df[colname+'_synthesized'][idx] = 1\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing on Restaurant.csv </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Open Date</th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>...</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>07/17/1999</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>IL</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5653753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02/14/2008</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>FC</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6923131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03/09/2013</td>\n",
       "      <td>Diyarbakır</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2055379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>02/02/2012</td>\n",
       "      <td>Tokat</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2675511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>05/09/2009</td>\n",
       "      <td>Gaziantep</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4316715.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   Open Date        City  City Group Type  P1   P2   P3   P4  P5  \\\n",
       "0   0  07/17/1999    İstanbul  Big Cities   IL   4  5.0  4.0  4.0   2   \n",
       "1   1  02/14/2008      Ankara  Big Cities   FC   4  5.0  4.0  4.0   1   \n",
       "2   2  03/09/2013  Diyarbakır       Other   IL   2  4.0  2.0  5.0   2   \n",
       "3   3  02/02/2012       Tokat       Other   IL   6  4.5  6.0  6.0   4   \n",
       "4   4  05/09/2009   Gaziantep       Other   IL   3  4.0  3.0  4.0   2   \n",
       "\n",
       "     ...      P29  P30  P31  P32  P33  P34  P35  P36  P37    revenue  \n",
       "0    ...      3.0    5    3    4    5    5    4    3    4  5653753.0  \n",
       "1    ...      3.0    0    0    0    0    0    0    0    0  6923131.0  \n",
       "2    ...      3.0    0    0    0    0    0    0    0    0  2055379.0  \n",
       "3    ...      7.5   25   12   10    6   18   12   12    6  2675511.0  \n",
       "4    ...      3.0    5    1    3    2    3    4    3    3  4316715.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.read_csv(\"Restaurant.csv\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3956086.,  3570392.,  6363241.,  7217634.,  3199619.,  4491607.,\n",
       "        3248660.,  4136425.,  2097022.,  3810007.,  2364478.,  3753720.,\n",
       "        7201784.,  3939804.,  3008199.,  4651866.,  3784230.,  2525375.,\n",
       "        4052733.,  6941173.,  8904084.,  3445076.,  6782425.,  4758476.,\n",
       "        3347767.,  1847826.,  4882985.,  4429512.,  1270499.,  2732645.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_df.copy()\n",
    "# List of random numbers (no repeats) between 1 and 137 and then delete A_follower_count[that row]   \n",
    "rows_to_delete = random.sample(range(137), 30)\n",
    "# Deleting values from those rows\n",
    "for x in rows_to_delete:\n",
    "    df['revenue'][x] = np.nan\n",
    "# Creating array of the correct answers from original data frame  \n",
    "deleted_answer_list = []\n",
    "for x in rows_to_delete:\n",
    "    deleted_answer_list.append(original_df['revenue'][x])\n",
    "# Converting it to array from a list so we can perform certain calculations\n",
    "deleted_answer_array = np.array(deleted_answer_list)\n",
    "deleted_answer_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "\n",
      "[[ 4859740.08350571]\n",
      " [ 3728457.71280077]\n",
      " [ 4747301.67852731]\n",
      " [ 3222950.8043993 ]\n",
      " [ 4561678.81569383]\n",
      " [ 4539431.13895401]\n",
      " [ 3997883.59249391]\n",
      " [ 4937836.34377644]\n",
      " [ 5759218.47930182]\n",
      " [ 5509910.54931136]\n",
      " [ 5339310.54251825]\n",
      " [ 5799161.564878  ]\n",
      " [ 4068655.21856287]\n",
      " [ 5832835.33173468]\n",
      " [ 4089367.20097733]\n",
      " [ 4078853.43726617]\n",
      " [ 3968482.16226212]\n",
      " [ 4153452.39903516]\n",
      " [ 4380404.21429641]\n",
      " [ 4164756.72078256]\n",
      " [ 5480252.50591854]\n",
      " [ 4185454.07835212]\n",
      " [ 3779801.40969928]\n",
      " [ 4994081.80228943]\n",
      " [ 4948974.7532436 ]\n",
      " [ 5257586.93332632]\n",
      " [ 5056732.56955768]\n",
      " [ 5426897.76439071]\n",
      " [ 5008856.98454723]\n",
      " [ 5118072.47283297]]\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "fillEmpty(df,42,1) # prediction problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other', 'Big Cities', 'Other', 'Other', 'Other', 'Other', 'Other',\n",
       "       'Big Cities', 'Other', 'Big Cities', 'Other', 'Big Cities',\n",
       "       'Big Cities', 'Other', 'Big Cities', 'Other', 'Other', 'Big Cities',\n",
       "       'Other', 'Big Cities', 'Big Cities', 'Other', 'Big Cities', 'Other',\n",
       "       'Big Cities', 'Big Cities', 'Big Cities', 'Big Cities', 'Other',\n",
       "       'Big Cities'], \n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = original_df.copy()\n",
    "# List of random numbers (no repeats) between 1 and 137 and then delete A_follower_count[that row]   \n",
    "rows_to_delete = random.sample(range(137), 30)\n",
    "# Deleting values from those rows\n",
    "for x in rows_to_delete:\n",
    "    df2['City Group'][x] = np.nan\n",
    "# Creating array of the correct answers from original data frame  \n",
    "deleted_answer_list = []\n",
    "for x in rows_to_delete:\n",
    "    deleted_answer_list.append(original_df['City Group'][x])\n",
    "# Converting it to array from a list so we can perform certain calculations\n",
    "deleted_answer_array_city_group = np.array(deleted_answer_list)\n",
    "deleted_answer_array_city_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "\n",
      "Training score:  1.0\n",
      "[ 0.  1.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# test the function\n",
    "fillEmpty(df2,3,0) # classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b> Testing on titanic_with_empties.csv </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       NaN       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\"titanic_with_empties.csv\")\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "\n",
      "Training score:  1.0\n",
      "[  15.   15.    5.  131.    3.    3.    1.   15.   23.    3.    4.    3.\n",
      "    5.    3.    5.    5.    3.    3.   23.   15.  131.   15.    6.  131.\n",
      "    5.    8.   16.   15.   15.    3.    3.    3.    9.    5.   26.    3.\n",
      "   15.    3.  131.   23.    3.    7.   15.    9.   14.   15.   26.    7.\n",
      "   15.    7.  115.    3.   15.    7.   15.   14.    7.   19.    3.   73.\n",
      "   15.   15.   26.   22.   15.   15.  131.   20.   14.    7.    3.   15.\n",
      "   15.   15.   15.   23.   15.   15.   22.   26.   15.   15.   15.   15.\n",
      "   15.   15.   15.   15.   23.    3.   15.    3.    3.   15.  131.   22.\n",
      "    7.   19.   15.   26.    3.   15.   15.   15.   15.   15.    3.   26.\n",
      "   22.   52.   15.    3.   15.    3.   15.   15.   26.   15.    3.   52.\n",
      "   45.   15.    3.   15.   29.   15.   15.   15.    7.    3.   22.   15.\n",
      "   15.   32.   26.    3.   50.    3.    3.    3.   15.    3.    7.   22.\n",
      "   15.    7.   52.    7.    3.    3.   34.    3.   15.   22.   15.    3.\n",
      "  131.    3.  131.   22.   15.    7.   15.   15.   73.    3.    3.    3.\n",
      "   15.   52.   15.   22.    3.    3.   26.   22.   73.   15.   45.   15.\n",
      "   15.   14.   15.   15.    7.   15.   52.    7.   15.   15.   26.   26.\n",
      "   15.   52.    3.    3.   22.   15.   15.   15.  101.   26.   15.    3.\n",
      "    3.    3.   38.  124.   26.  131.    7.  131.   52.    7.   15.   54.\n",
      "   15.   52.  131.   52.   45.    7.   23.  131.   15.   15.   73.   73.\n",
      "   73.   15.   52.    3.   47.    3.   15.   77.   15.  131.   23.   15.\n",
      "   73.   57.   52.   26.   15.   26.   73.   26.   52.   15.   15.   22.\n",
      "   26.    7.   15.   23.    3.    3.   60.   73.   52.   14.   14.   52.\n",
      "   52.   14.    3.   73.   73.    3.    3.   15.   15.   52.   73.   73.\n",
      "   23.   26.   52.   15.    3.   15.   14.  131.   15.   15.   51.    3.\n",
      "    9.   15.   15.   15.  122.    3.   73.   13.   73.   26.    7.   52.\n",
      "  131.   52.   73.   73.   15.   73.   26.   15.   14.   73.   73.    3.\n",
      "    3.   73.   26.  118.   26.   15.    7.   73.  131.   45.   73.   73.\n",
      "   26.   14.   14.    3.   73.   15.   73.    3.    3.   15.   26.   26.\n",
      "  131.   73.   26.   15.    3.   72.   14.   26.   73.   15.   14.   73.\n",
      "   14.   11.    3.   26.   73.   73.   73.   14.  131.   73.   52.   73.\n",
      "   15.   45.   79.  131.    3.   15.   73.   26.   73.   26.   15.   15.\n",
      "    3.    7.   14.   73.   52.    7.   73.    3.   73.   15.   84.   73.\n",
      "    3.   73.   15.   15.  131.  131.    3.   26.   88.   15.    3.  131.\n",
      "   73.   86.   15.  131.   26.   73.   15.   15.   15.  131.   14.   14.\n",
      "   15.   26.   15.   15.    3.   73.   26.   77.   73.    7.    7.   26.\n",
      "  105.   26.   52.   23.   26.   26.  131.   73.   15.  105.   91.   14.\n",
      "  131.   14.   14.   73.   73.   15.   15.    3.   15.   73.   14.  131.\n",
      "   73.   15.   14.   73.   73.   26.   26.   73.   52.   15.   73.   15.\n",
      "  118.  131.   26.   23.   26.   15.   15.   26.   73.   89.   14.  100.\n",
      "  111.   73.  108.   26.    3.   15.    3.  131.   73.   26.   15.    3.\n",
      "   22.   15.   73.   15.  111.   22.   15.  131.  118.  111.    7.   14.\n",
      "   73.   26.    3.   73.   15.    7.   73.    3.   15.   15.   15.   73.\n",
      "   26.   15.  131.  131.    9.   73.    3.   15.    7.  118.  118.   73.\n",
      "    9.   15.   15.  118.  112.  130.   22.   22.   15.   15.   73.    3.\n",
      "  131.   15.    7.   26.  115.    7.   15.   15.    3.   73.   15.   63.\n",
      "  118.  118.  131.   52.  131.   15.   26.   14.  116.    3.   15.   22.\n",
      "  131.   15.   26.   15.   22.   22.   15.    7.  131.   26.    3.    3.\n",
      "   22.   22.   22.  128.    3.   15.   15.  128.  131.    3.   22.  131.\n",
      "   26.  131.   15.   72.   26.   15.   22.  131.   15.   15.   15.   15.\n",
      "  133.  131.  131.  131.   15.  131.  131.   72.   15.    3.  131.  131.\n",
      "  128.   15.   15.   15.    7.    3.  131.   26.    7.  133.   15.   22.\n",
      "  131.  131.    3.   22.   26.   53.   15.   15.   15.   22.   15.  111.\n",
      "  130.    7.  131.  131.   26.  131.    7.  128.  137.    7.  131.    3.\n",
      "   32.  131.  128.   53.  131.   15.   15.   15.  131.   43.   15.   22.\n",
      "   56.  131.   15.  131.    7.  131.   26.    7.  131.    3.   26.  128.\n",
      "  132.    3.  131.  128.   22.    7.   22.   22.   52.  131.    3.   15.\n",
      "  131.   14.   15.   15.   15.  131.   26.  131.   15.   22.   15.  131.\n",
      "   22.   72.  131.]\n"
     ]
    }
   ],
   "source": [
    "# test the function on Cabin\n",
    "fillEmpty(titanic_df,10,0) # classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "\n",
      "Training score:  0.991907514451\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# test the function on Survived\n",
    "fillEmpty(titanic_df,1,0) # classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing on iris_with_empties.csv </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width species\n",
       "0           NaN          3.5  setosa\n",
       "1           4.9          3.0  setosa\n",
       "2           4.7          3.2     NaN\n",
       "3           4.6          3.1  setosa\n",
       "4           5.0          3.6  setosa"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.read_csv(\"iris_with_empties.csv\")\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "\n",
      "[[ 5.58385052]\n",
      " [ 5.5814514 ]\n",
      " [ 5.59344702]\n",
      " [ 5.5814514 ]\n",
      " [ 5.57425403]\n",
      " [ 5.867928  ]\n",
      " [ 6.18319407]\n",
      " [ 6.18799232]\n",
      " [ 6.1759967 ]]\n"
     ]
    }
   ],
   "source": [
    "# test the function on sepal_length\n",
    "fillEmpty(iris_df,0,1) # prediction problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "\n",
      "Training score:  0.914285714286\n",
      "[ 0.  0.  0.  0.  1.  0.  1.  2.  1.  2.]\n"
     ]
    }
   ],
   "source": [
    "# test the function on species\n",
    "fillEmpty(iris_df,2,0) # classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing on energy_with_empties.csv </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8     Y1\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0    NaN\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_df = pd.read_csv(\"energy_with_empties.csv\")\n",
    "energy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "\n",
      "[[ 27.65300887]\n",
      " [ 24.87584998]\n",
      " [ 25.78440438]\n",
      " [ 14.38551765]\n",
      " [ 28.78776467]\n",
      " [ 30.32084643]\n",
      " [ 16.97896861]\n",
      " [ 15.43098267]\n",
      " [ 26.9657231 ]\n",
      " [ 16.18810566]\n",
      " [ 28.08441194]\n",
      " [ 27.36951089]\n",
      " [ 17.69993448]\n",
      " [ 17.32018039]\n",
      " [ 31.90703585]\n",
      " [ 32.93583091]\n",
      " [ 28.54489047]\n",
      " [ 29.35342327]\n",
      " [ 16.12444674]\n",
      " [ 18.8320092 ]\n",
      " [ 33.38292355]\n",
      " [ 19.19249214]]\n"
     ]
    }
   ],
   "source": [
    "# test the function on Y1\n",
    "fillEmpty(energy_df,8,1) # prediction problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing on diabetes_with_empties.csv </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimesPregnant</th>\n",
       "      <th>glucoseLevel</th>\n",
       "      <th>BP</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>IsDiabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  IsDiabetic\n",
       "0              6         148.0  72        0  33.6     0.627  50.0           1\n",
       "1              1           NaN  66        0  26.6     0.351  31.0           0\n",
       "2              8         183.0  64        0  23.3     0.672   NaN           1\n",
       "3              1           NaN  66       94  28.1     0.167  21.0           0\n",
       "4              0         137.0  40      168  43.1     2.288  33.0           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv(\"diabetes_with_empties.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "\n",
      "[[ 110.22586021]\n",
      " [ 111.23619473]\n",
      " [ 126.64943274]\n",
      " [ 165.81852911]\n",
      " [ 139.0678635 ]\n",
      " [ 123.74505246]\n",
      " [ 110.25503689]\n",
      " [ 126.02159883]\n",
      " [ 108.0717632 ]\n",
      " [ 118.59162567]\n",
      " [ 131.44741518]\n",
      " [ 108.10021271]\n",
      " [ 129.84577199]\n",
      " [ 129.429291  ]\n",
      " [ 109.19763176]\n",
      " [ 130.82853592]\n",
      " [ 132.6827452 ]\n",
      " [ 120.15041996]\n",
      " [ 140.95280942]\n",
      " [ 133.10629116]\n",
      " [ 109.80068339]\n",
      " [ 123.02784283]\n",
      " [ 116.63436823]\n",
      " [ 134.66353125]\n",
      " [ 106.84183967]\n",
      " [ 107.16755821]\n",
      " [ 114.14224633]\n",
      " [ 120.39957272]\n",
      " [ 120.45788445]\n",
      " [ 130.6438027 ]\n",
      " [ 116.08773432]\n",
      " [ 118.55309261]\n",
      " [ 111.51018416]\n",
      " [ 143.31758113]\n",
      " [ 118.88380431]\n",
      " [ 132.85496529]\n",
      " [ 122.27160436]\n",
      " [ 116.21901929]\n",
      " [ 108.67538893]\n",
      " [ 117.79693612]\n",
      " [ 116.8858277 ]]\n"
     ]
    }
   ],
   "source": [
    "# test the function on glucoseLevel\n",
    "fillEmpty(diabetes_df,1,1) # prediction problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "\n",
      "Training score:  1.0\n",
      "[ 34.  38.  21.  22.  56.  21.  28.  52.  21.  35.  22.  28.  46.  37.  31.\n",
      "  21.  30.  33.  21.  52.  31.  43.  28.  22.  33.  23.  22.  28.  49.  22.\n",
      "  24.  21.  57.  58.  29.  25.  40.  21.  22.  24.  40.]\n"
     ]
    }
   ],
   "source": [
    "# test the function on age\n",
    "fillEmpty(diabetes_df,6,0) # classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "\n",
      "Training score:  1.0\n",
      "[ 36.  33.  25.  22.  67.  21.  28.  26.  25.  58.  22.  22.  46.  37.  22.\n",
      "  21.  29.  23.  21.  52.  28.  21.  28.  21.  33.  24.  24.  24.  39.  25.\n",
      "  37.  24.  57.  37.  29.  25.  31.  21.  22.  24.  42.]\n"
     ]
    }
   ],
   "source": [
    "# new test: testing the same, but for fillEmpty2\n",
    "fillEmpty2(diabetes_df,'Age',0) # classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying...\n",
      "\n",
      "Training score:  1.0\n",
      "     TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  \\\n",
      "0                6    148.000000  72        0  33.6     0.627  50.0   \n",
      "1                1    121.078404  66        0  26.6     0.351  31.0   \n",
      "2                8    183.000000  64        0  23.3     0.672  41.0   \n",
      "3                1    121.078404  66       94  28.1     0.167  21.0   \n",
      "4                0    137.000000  40      168  43.1     2.288  33.0   \n",
      "5                5    116.000000  74        0  25.6     0.201  30.0   \n",
      "6                3     78.000000  50       88  31.0     0.248  26.0   \n",
      "7               10    115.000000   0        0  35.3     0.134  29.0   \n",
      "8                2    197.000000  70      543  30.5     0.158  53.0   \n",
      "9                8    121.078404  96        0   0.0     0.232  54.0   \n",
      "10               4    110.000000  92        0  37.6     0.191  26.0   \n",
      "11              10    168.000000  74        0  38.0     0.537  34.0   \n",
      "12              10    139.000000  80        0  27.1     1.441  57.0   \n",
      "13               1    121.078404  60      846  30.1     0.398  59.0   \n",
      "14               5    166.000000  72      175  25.8     0.587  51.0   \n",
      "15               7    100.000000   0        0  30.0     0.484  32.0   \n",
      "16               0    121.078404  84      230  45.8     0.551  31.0   \n",
      "17               7    107.000000  74        0  29.6     0.254  31.0   \n",
      "18               1    103.000000  30       83  43.3     0.183  33.0   \n",
      "19               1    115.000000  70       96  34.6     0.529  25.0   \n",
      "20               3    126.000000  88      235  39.3     0.704  27.0   \n",
      "21               8     99.000000  84        0  35.4     0.388  50.0   \n",
      "22               7    196.000000  90        0  39.8     0.451  41.0   \n",
      "23               9    119.000000  80        0  29.0     0.263  29.0   \n",
      "24              11    143.000000  94      146  36.6     0.254  51.0   \n",
      "25              10    125.000000  70      115  31.1     0.205  41.0   \n",
      "26               7    147.000000  76        0  39.4     0.257  43.0   \n",
      "27               1     97.000000  66      140  23.2     0.487  26.0   \n",
      "28              13    121.078404  82      110  22.2     0.245  57.0   \n",
      "29               5    117.000000  92        0  34.1     0.337  38.0   \n",
      "..             ...           ...  ..      ...   ...       ...   ...   \n",
      "738              2     99.000000  60      160  36.6     0.453  24.0   \n",
      "739              1    102.000000  74        0  39.5     0.293  42.0   \n",
      "740             11    120.000000  80      150  42.3     0.785  48.0   \n",
      "741              3    102.000000  44       94  30.8     0.400  26.0   \n",
      "742              1    109.000000  58      116  28.5     0.219  22.0   \n",
      "743              9    140.000000  94        0  32.7     0.734  45.0   \n",
      "744             13    153.000000  88      140  40.6     1.174  39.0   \n",
      "745             12    100.000000  84      105  30.0     0.488  46.0   \n",
      "746              1    147.000000  94        0  49.3     0.358  27.0   \n",
      "747              1     81.000000  74       57  46.3     1.096  32.0   \n",
      "748              3    187.000000  70      200  36.4     0.408  36.0   \n",
      "749              6    162.000000  62        0  24.3     0.178  50.0   \n",
      "750              4    136.000000  70        0  31.2     1.182  22.0   \n",
      "751              1    121.000000  78       74  39.0     0.261  28.0   \n",
      "752              3    108.000000  62        0  26.0     0.223  25.0   \n",
      "753              0    181.000000  88      510  43.3     0.222  26.0   \n",
      "754              8    154.000000  78        0  32.4     0.443  45.0   \n",
      "755              1    128.000000  88      110  36.5     1.057  37.0   \n",
      "756              7    137.000000  90        0  32.0     0.391  39.0   \n",
      "757              0    123.000000  72        0  36.3     0.258  52.0   \n",
      "758              1    106.000000  76        0  37.5     0.197  26.0   \n",
      "759              6    190.000000  92        0  35.5     0.278  66.0   \n",
      "760              2     88.000000  58       16  28.4     0.766  22.0   \n",
      "761              9    170.000000  74        0  44.0     0.403  43.0   \n",
      "762              9     89.000000  62        0  22.5     0.142  33.0   \n",
      "763             10    101.000000  76      180  32.9     0.171  63.0   \n",
      "764              2    122.000000  70        0  36.8     0.340  27.0   \n",
      "765              5    121.000000  72      112  26.2     0.245  37.0   \n",
      "766              1    126.000000  60        0  30.1     0.349  47.0   \n",
      "767              1     93.000000  70        0  30.4     0.315  23.0   \n",
      "\n",
      "     IsDiabetic  Age_synthesized  \n",
      "0             1                0  \n",
      "1             0                0  \n",
      "2             1                1  \n",
      "3             0                0  \n",
      "4             1                0  \n",
      "5             0                0  \n",
      "6             1                0  \n",
      "7             0                0  \n",
      "8             1                0  \n",
      "9             1                0  \n",
      "10            0                1  \n",
      "11            1                0  \n",
      "12            0                0  \n",
      "13            1                0  \n",
      "14            1                0  \n",
      "15            1                0  \n",
      "16            1                0  \n",
      "17            1                0  \n",
      "18            0                0  \n",
      "19            1                1  \n",
      "20            0                0  \n",
      "21            0                0  \n",
      "22            1                0  \n",
      "23            1                0  \n",
      "24            1                0  \n",
      "25            1                0  \n",
      "26            1                0  \n",
      "27            0                1  \n",
      "28            0                0  \n",
      "29            0                0  \n",
      "..          ...              ...  \n",
      "738           0                1  \n",
      "739           1                0  \n",
      "740           1                0  \n",
      "741           0                0  \n",
      "742           0                0  \n",
      "743           1                0  \n",
      "744           0                0  \n",
      "745           0                0  \n",
      "746           1                0  \n",
      "747           0                0  \n",
      "748           1                0  \n",
      "749           1                0  \n",
      "750           1                0  \n",
      "751           0                0  \n",
      "752           0                0  \n",
      "753           1                0  \n",
      "754           1                0  \n",
      "755           1                0  \n",
      "756           0                0  \n",
      "757           1                0  \n",
      "758           0                0  \n",
      "759           1                0  \n",
      "760           0                0  \n",
      "761           1                0  \n",
      "762           0                0  \n",
      "763           0                0  \n",
      "764           0                0  \n",
      "765           0                1  \n",
      "766           1                0  \n",
      "767           0                0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# new test: testing the same, but for fillEmptyNew\n",
    "fillEmptyNew(diabetes_df,'Age',0) # classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
